{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import string\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if not c.isdigit()])      \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "data = pd.read_csv('./test.csv')\n",
    "data = data.dropna()\n",
    "data['text'] = data.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_bert(sequence):\n",
    "    model = pipeline('fill-mask', model='bert-base-uncased')\n",
    "    pred = model(sequence + ' [MASK]')\n",
    "    return pred[0]['token_str']\n",
    "\n",
    "def predict_next_word_gpt2(sequence):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits[:, -1, :]\n",
    "    pred_id = torch.argmax(logits).item()\n",
    "    pred_word = tokenizer.decode(pred_id)\n",
    "    return pred_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without . version\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "actual_words = []\n",
    "predictions_bert = []\n",
    "predictions_gpt2 = []\n",
    "\n",
    "for idx, doc in tqdm(enumerate(data['text']), total=len(data['text']), desc=\"Processing Text\"):\n",
    "    sentences = doc.split('.')\n",
    "    longest_sentence = max(sentences, key=lambda s: len(s.split()))\n",
    "    longest_sentence = preprocess_text(longest_sentence)\n",
    "    words = longest_sentence.split()\n",
    "    \n",
    "    if len(words) > 1:\n",
    "        prompt = ' '.join(words[:-1])\n",
    "        actual_word = words[-1]\n",
    "        actual_words.append(actual_word)\n",
    "        predictions_bert.append(predict_next_word_bert(prompt))\n",
    "        predictions_gpt2.append(predict_next_word_gpt2(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Actual Words\": actual_words,\n",
    "    \"BERT Predictions\": predictions_bert,\n",
    "    \"GPT-2 Predictions\": predictions_gpt2,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "output_path = \"./predictions_comparison_without_punc.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actual_words):\n",
    "    correct = sum([1 for pred, actual in zip(predictions, actual_words) if pred == actual])\n",
    "    return correct / len(actual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bert = calculate_accuracy(predictions_bert, actual_words)\n",
    "accuracy_gpt2 = calculate_accuracy(predictions_gpt2, actual_words)\n",
    "print(f\"BERT Accuracy: {accuracy_bert}\")\n",
    "print(f\"GPT-2 Accuracy: {accuracy_gpt2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_bert = []\n",
    "process_gpt = []\n",
    "for index in range(len(predictions_bert)):\n",
    "    process_bert.append(preprocess_text(predictions_bert[index]))\n",
    "    process_gpt.append(preprocess_text(predictions_gpt2[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bert = calculate_accuracy(process_bert, actual_words)\n",
    "accuracy_gpt2 = calculate_accuracy(process_gpt, actual_words)\n",
    "print(f\"BERT Accuracy: {accuracy_bert}\")\n",
    "print(f\"GPT-2 Accuracy: {accuracy_gpt2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with . version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if not c.isdigit()])      \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "data = pd.read_csv('./test.csv')\n",
    "data = data.dropna()\n",
    "data['text'] = data.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "actual_wordsv2 = []\n",
    "predictions_bertv2 = []\n",
    "predictions_gpt2v2 = []\n",
    "\n",
    "for idx, doc in tqdm(enumerate(data['text']), total=len(data['text']), desc=\"Processing Text\"):\n",
    "    sentences = doc.split('.')\n",
    "    longest_sentence = max(sentences, key=lambda s: len(s.split()))\n",
    "    \n",
    "    longest_sentence = preprocess_text(longest_sentence)\n",
    "    longest_sentence = longest_sentence + \".\"\n",
    "    \n",
    "    words = longest_sentence.split()\n",
    "    if len(words) > 1:\n",
    "        prompt = ' '.join(words[:-1])\n",
    "        actual_word = words[-1]\n",
    "        actual_wordsv2.append(actual_word)\n",
    "        predictions_bertv2.append(predict_next_word_bert(prompt))\n",
    "        predictions_gpt2v2.append(predict_next_word_gpt2(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Actual Words\": actual_wordsv2,\n",
    "    \"BERT Predictions\": predictions_bertv2,\n",
    "    \"GPT-2 Predictions\": predictions_gpt2v2,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "output_path = \"./predictions_comparison_with_punc.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bert2 = calculate_accuracy(predictions_bertv2, actual_wordsv2)\n",
    "accuracy_gpt22 = calculate_accuracy(predictions_gpt2v2, actual_wordsv2)\n",
    "print(f\"BERT Accuracy: {accuracy_bert2}\")\n",
    "print(f\"GPT-2 Accuracy: {accuracy_gpt22}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_bertv2 = []\n",
    "process_gptv2 = []\n",
    "actual_wordsv22 = []\n",
    "for index in range(len(predictions_bert)):\n",
    "    process_bertv2.append(' '.join(predictions_bertv2[index].split()))\n",
    "    process_gptv2.append(' '.join(predictions_gpt2v2[index].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bert2 = calculate_accuracy(process_bertv2, actual_wordsv2)\n",
    "accuracy_gpt22 = calculate_accuracy(process_gptv2, actual_wordsv2)\n",
    "print(f\"BERT Accuracy: {accuracy_bert2}\")\n",
    "print(f\"GPT-2 Accuracy: {accuracy_gpt22}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
